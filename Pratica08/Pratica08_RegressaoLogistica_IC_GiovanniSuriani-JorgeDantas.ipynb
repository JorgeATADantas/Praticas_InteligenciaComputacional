{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7QYddtZjGH_s"
   },
   "source": [
    "**Prática 08 – Regressão Logistica**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ghA_ViPQGH3r"
   },
   "source": [
    "**Alunos:\n",
    "\n",
    "GIOVANNI SURIANI FERREIRA\n",
    "\n",
    "JORGE ALIOMAR TROCOLI ABDON DANTAS**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lFr8QeByGHqO"
   },
   "source": [
    "Objetivo:<br>\n",
    "- Aplique classificador Regressão Logística aos dados seu Trabalho Prático.\n",
    "    - (https://scikitlearn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html)\n",
    "- Compare os resultados da Regressão Logística com os resultados do XGBoost (ou equivalente)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jzZ2MAv0hN8i"
   },
   "source": [
    "# PREPARAÇÃO DA BASE DE DADOS - Todos os dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "G3ZCBI41MkU5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extension for Scikit-learn* enabled (https://github.com/uxlfoundation/scikit-learn-intelex)\n"
     ]
    }
   ],
   "source": [
    "#Importando Bibliotecas Pandas e Numpy\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Otimizador Giovanni\n",
    "from sklearnex import patch_sklearn\n",
    "patch_sklearn()\n",
    "\n",
    "#CSV_PATH = \"/home/gi/Desktop/Semestre8/Inteligencia_Computacional/TP1_csvs\" # Path Giovanni\n",
    "#validacao_cruzada_num_folds = 10 # Para Giovanni\n",
    "#CSV_PATH = \"E:/Documentos/CEFET/OneDrive/Documentos/2ECOM067_INTELIGENCIA-COMPUTACIONAL-I_T01/TP1/bases/\" # Path Jorge\n",
    "CSV_PATH = \"C:/Users/LUCAR/Documents/Jorge/IC/bases\" # Path Jorge\n",
    "validacao_cruzada_num_folds = 10     # Para Jorge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "232RQBEu3mWD"
   },
   "outputs": [],
   "source": [
    "#Carregando Base de dados principal - Treino\n",
    "df_train = pd.read_csv(f\"{CSV_PATH}/df_train_full.csv\")\n",
    "df_test  = pd.read_csv(f\"{CSV_PATH}/df_test_full.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DJjJF_XGhN8u"
   },
   "source": [
    "# PREPARAÇÃO DA BASE DE DADOS - Amostra"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verificação com colunas com muitos nulos (mais que 25%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calcular o % de nulos por coluna\n",
    "percentual_nulos = round(df_train.isnull().mean(),2)\n",
    "\n",
    "# Verificar quais colunas têm mais de 25% de valores nulos\n",
    "colunas_com_muitos_nulos = percentual_nulos[percentual_nulos > 0.25].index.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exclusão das coluna com muitos nulos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_tratado = df_train.copy()\n",
    "df_test_tratado  = df_test.copy()\n",
    "\n",
    "# Excluir colunas do treino\n",
    "df_train_tratado = df_train_tratado.drop(columns=colunas_com_muitos_nulos)\n",
    "\n",
    "# Excluir colunas do teste\n",
    "df_test_tratado = df_test_tratado.drop(columns=colunas_com_muitos_nulos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Substitutição dos nulos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de valores nulos restantes nos dados de treino: 0\n"
     ]
    }
   ],
   "source": [
    "#Tratar colunas numéricas - Treino\n",
    "for coluna in df_train_tratado.select_dtypes(include=['number']).columns:\n",
    "    if df_train_tratado[coluna].isnull().any():\n",
    "        if pd.api.types.is_float_dtype(df_train_tratado[coluna]): # Se tipo de dado for float, realizará a média\n",
    "            media = df_train_tratado[coluna].mean()\n",
    "            df_train_tratado[coluna] = df_train_tratado[coluna].fillna(media)\n",
    "        elif pd.api.types.is_integer_dtype(df_train_tratado[coluna]): # Se tipo de dado for int, realizará a moda\n",
    "            moda = df_train_tratado[coluna].mode(dropna=True)\n",
    "            if not moda.empty:\n",
    "                df_train_tratado[coluna] = df_train_tratado[coluna].fillna(moda[0])\n",
    "\n",
    "#Tratar colunas categóricas com a moda  - Treino\n",
    "colunas_categoricas = df_train_tratado.select_dtypes(include=['object', 'category']).columns\n",
    "\n",
    "for coluna in colunas_categoricas:\n",
    "    if df_train_tratado[coluna].isnull().any():\n",
    "        moda = df_train_tratado[coluna].mode(dropna=True)\n",
    "        if not moda.empty:\n",
    "            df_train_tratado[coluna] = df_train_tratado[coluna].fillna(moda[0])\n",
    "\n",
    "#Validação - Treino\n",
    "print(\"Total de valores nulos restantes nos dados de treino:\", df_train_tratado.isnull().sum().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de valores nulos restantes nos dados de teste: 0\n"
     ]
    }
   ],
   "source": [
    "#Tratar colunas numéricas - Teste\n",
    "for coluna in df_test_tratado.select_dtypes(include=['number']).columns:\n",
    "    if df_test_tratado[coluna].isnull().any():\n",
    "        if pd.api.types.is_float_dtype(df_test_tratado[coluna]): # Se tipo de dado for float, realizará a média\n",
    "            media = df_test_tratado[coluna].mean()\n",
    "            df_test_tratado[coluna] = df_test_tratado[coluna].fillna(media)\n",
    "        elif pd.api.types.is_integer_dtype(df_test_tratado[coluna]): # Se tipo de dado for int, realizará a moda\n",
    "            moda = df_test_tratado[coluna].mode(dropna=True)\n",
    "            if not moda.empty:\n",
    "                df_test_tratado[coluna] = df_test_tratado[coluna].fillna(moda[0])\n",
    "\n",
    "#Tratar colunas categóricas com a moda  - Teste\n",
    "colunas_categoricas = df_test_tratado.select_dtypes(include=['object', 'category']).columns\n",
    "\n",
    "for coluna in colunas_categoricas:\n",
    "    if df_test_tratado[coluna].isnull().any():\n",
    "        moda = df_test_tratado[coluna].mode(dropna=True)\n",
    "        if not moda.empty:\n",
    "            df_test_tratado[coluna] = df_test_tratado[coluna].fillna(moda[0])\n",
    "\n",
    "#Validação - Treino\n",
    "print(\"Total de valores nulos restantes nos dados de teste:\", df_test_tratado.isnull().sum().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Realizar transformação das variáveis categóricas em variáveis númericas (Label Enconder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importação da biblioteca\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le = LabelEncoder()\n",
    "\n",
    "#Busca dos atributos do tipo object e category - TREINO\n",
    "colunas_categoricas_train = df_train_tratado.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "\n",
    "#Concatenação dos dataframes treino e teste com o objetivo de realizar um label enconder com códigos únicos\n",
    "df_all = pd.concat([df_train_tratado, df_test_tratado], axis=0)\n",
    "\n",
    "for coluna in colunas_categoricas_train:\n",
    "    le.fit(df_all[coluna])\n",
    "    df_train_tratado[coluna] = le.transform(df_train_tratado[coluna].astype(str))\n",
    "    df_test_tratado[coluna] = le.transform(df_test_tratado[coluna].astype(str))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fazer amostragem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "42r9hUZuhN8v"
   },
   "outputs": [],
   "source": [
    "#Amostra df_train\n",
    "df_train_tratado_amostrado = df_train_tratado.sample(frac=0.4, random_state=42)  # Para Jorge\n",
    "#df_train_tratado_amostrado = df_train_tratado.sample(frac=1, random_state=42) # Para Giovanni"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Divisão de Treino/Teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "kbmaTkxFhN8v"
   },
   "outputs": [],
   "source": [
    "#Divisão treino / teste\n",
    "X_train = df_train_tratado_amostrado.drop(columns={\"TARGET\"})\n",
    "y_train = df_train_tratado_amostrado.TARGET\n",
    "X_test  = df_test_tratado.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Verificar se y_train tem 0 e 1. Se true, OK dá para continuar a modelagem\n",
    "#                                Se false, ajustar para que tenha 0 e 1\n",
    "set(y_train) == {0, 1}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalização Padrão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 123004 entries, 245895 to 170348\n",
      "Data columns (total 131 columns):\n",
      " #    Column                       Non-Null Count   Dtype  \n",
      "---   ------                       --------------   -----  \n",
      " 0    SK_ID_CURR                   123004 non-null  int64  \n",
      " 1    NAME_CONTRACT_TYPE           123004 non-null  int64  \n",
      " 2    CODE_GENDER                  123004 non-null  int64  \n",
      " 3    FLAG_OWN_CAR                 123004 non-null  int64  \n",
      " 4    FLAG_OWN_REALTY              123004 non-null  int64  \n",
      " 5    CNT_CHILDREN                 123004 non-null  int64  \n",
      " 6    AMT_INCOME_TOTAL             123004 non-null  float64\n",
      " 7    AMT_CREDIT                   123004 non-null  float64\n",
      " 8    AMT_ANNUITY                  123004 non-null  float64\n",
      " 9    AMT_GOODS_PRICE              123004 non-null  float64\n",
      " 10   NAME_TYPE_SUITE              123004 non-null  int64  \n",
      " 11   NAME_INCOME_TYPE             123004 non-null  int64  \n",
      " 12   NAME_EDUCATION_TYPE          123004 non-null  int64  \n",
      " 13   NAME_FAMILY_STATUS           123004 non-null  int64  \n",
      " 14   NAME_HOUSING_TYPE            123004 non-null  int64  \n",
      " 15   REGION_POPULATION_RELATIVE   123004 non-null  float64\n",
      " 16   DAYS_BIRTH                   123004 non-null  int64  \n",
      " 17   DAYS_EMPLOYED                123004 non-null  int64  \n",
      " 18   DAYS_REGISTRATION            123004 non-null  float64\n",
      " 19   DAYS_ID_PUBLISH              123004 non-null  int64  \n",
      " 20   FLAG_MOBIL                   123004 non-null  int64  \n",
      " 21   FLAG_EMP_PHONE               123004 non-null  int64  \n",
      " 22   FLAG_WORK_PHONE              123004 non-null  int64  \n",
      " 23   FLAG_CONT_MOBILE             123004 non-null  int64  \n",
      " 24   FLAG_PHONE                   123004 non-null  int64  \n",
      " 25   FLAG_EMAIL                   123004 non-null  int64  \n",
      " 26   CNT_FAM_MEMBERS              123004 non-null  float64\n",
      " 27   REGION_RATING_CLIENT         123004 non-null  int64  \n",
      " 28   REGION_RATING_CLIENT_W_CITY  123004 non-null  int64  \n",
      " 29   WEEKDAY_APPR_PROCESS_START   123004 non-null  int64  \n",
      " 30   HOUR_APPR_PROCESS_START      123004 non-null  int64  \n",
      " 31   REG_REGION_NOT_LIVE_REGION   123004 non-null  int64  \n",
      " 32   REG_REGION_NOT_WORK_REGION   123004 non-null  int64  \n",
      " 33   LIVE_REGION_NOT_WORK_REGION  123004 non-null  int64  \n",
      " 34   REG_CITY_NOT_LIVE_CITY       123004 non-null  int64  \n",
      " 35   REG_CITY_NOT_WORK_CITY       123004 non-null  int64  \n",
      " 36   LIVE_CITY_NOT_WORK_CITY      123004 non-null  int64  \n",
      " 37   ORGANIZATION_TYPE            123004 non-null  int64  \n",
      " 38   EXT_SOURCE_2                 123004 non-null  float64\n",
      " 39   EXT_SOURCE_3                 123004 non-null  float64\n",
      " 40   OBS_30_CNT_SOCIAL_CIRCLE     123004 non-null  float64\n",
      " 41   DEF_30_CNT_SOCIAL_CIRCLE     123004 non-null  float64\n",
      " 42   OBS_60_CNT_SOCIAL_CIRCLE     123004 non-null  float64\n",
      " 43   DEF_60_CNT_SOCIAL_CIRCLE     123004 non-null  float64\n",
      " 44   DAYS_LAST_PHONE_CHANGE       123004 non-null  float64\n",
      " 45   FLAG_DOCUMENT_2              123004 non-null  int64  \n",
      " 46   FLAG_DOCUMENT_3              123004 non-null  int64  \n",
      " 47   FLAG_DOCUMENT_4              123004 non-null  int64  \n",
      " 48   FLAG_DOCUMENT_5              123004 non-null  int64  \n",
      " 49   FLAG_DOCUMENT_6              123004 non-null  int64  \n",
      " 50   FLAG_DOCUMENT_7              123004 non-null  int64  \n",
      " 51   FLAG_DOCUMENT_8              123004 non-null  int64  \n",
      " 52   FLAG_DOCUMENT_9              123004 non-null  int64  \n",
      " 53   FLAG_DOCUMENT_10             123004 non-null  int64  \n",
      " 54   FLAG_DOCUMENT_11             123004 non-null  int64  \n",
      " 55   FLAG_DOCUMENT_12             123004 non-null  int64  \n",
      " 56   FLAG_DOCUMENT_13             123004 non-null  int64  \n",
      " 57   FLAG_DOCUMENT_14             123004 non-null  int64  \n",
      " 58   FLAG_DOCUMENT_15             123004 non-null  int64  \n",
      " 59   FLAG_DOCUMENT_16             123004 non-null  int64  \n",
      " 60   FLAG_DOCUMENT_17             123004 non-null  int64  \n",
      " 61   FLAG_DOCUMENT_18             123004 non-null  int64  \n",
      " 62   FLAG_DOCUMENT_19             123004 non-null  int64  \n",
      " 63   FLAG_DOCUMENT_20             123004 non-null  int64  \n",
      " 64   FLAG_DOCUMENT_21             123004 non-null  int64  \n",
      " 65   AMT_REQ_CREDIT_BUREAU_HOUR   123004 non-null  float64\n",
      " 66   AMT_REQ_CREDIT_BUREAU_DAY    123004 non-null  float64\n",
      " 67   AMT_REQ_CREDIT_BUREAU_WEEK   123004 non-null  float64\n",
      " 68   AMT_REQ_CREDIT_BUREAU_MON    123004 non-null  float64\n",
      " 69   AMT_REQ_CREDIT_BUREAU_QRT    123004 non-null  float64\n",
      " 70   AMT_REQ_CREDIT_BUREAU_YEAR   123004 non-null  float64\n",
      " 71   SK_ID_BUREAU                 123004 non-null  int64  \n",
      " 72   CREDIT_ACTIVE                123004 non-null  int64  \n",
      " 73   CREDIT_CURRENCY              123004 non-null  int64  \n",
      " 74   DAYS_CREDIT                  123004 non-null  int64  \n",
      " 75   CREDIT_DAY_OVERDUE           123004 non-null  int64  \n",
      " 76   DAYS_CREDIT_ENDDATE          123004 non-null  float64\n",
      " 77   CNT_CREDIT_PROLONG           123004 non-null  int64  \n",
      " 78   AMT_CREDIT_SUM               123004 non-null  float64\n",
      " 79   AMT_CREDIT_SUM_DEBT          123004 non-null  float64\n",
      " 80   AMT_CREDIT_SUM_OVERDUE       123004 non-null  float64\n",
      " 81   CREDIT_TYPE                  123004 non-null  int64  \n",
      " 82   DAYS_CREDIT_UPDATE           123004 non-null  int64  \n",
      " 83   MONTHS_BALANCE               123004 non-null  int64  \n",
      " 84   STATUS                       123004 non-null  int64  \n",
      " 85   SK_ID_PREV                   123004 non-null  int64  \n",
      " 86   AMT_APPLICATION              123004 non-null  float64\n",
      " 87   FLAG_LAST_APPL_PER_CONTRACT  123004 non-null  int64  \n",
      " 88   NFLAG_LAST_APPL_IN_DAY       123004 non-null  int64  \n",
      " 89   NAME_CASH_LOAN_PURPOSE       123004 non-null  int64  \n",
      " 90   NAME_CONTRACT_STATUS         123004 non-null  int64  \n",
      " 91   DAYS_DECISION                123004 non-null  int64  \n",
      " 92   NAME_PAYMENT_TYPE            123004 non-null  int64  \n",
      " 93   CODE_REJECT_REASON           123004 non-null  int64  \n",
      " 94   NAME_CLIENT_TYPE             123004 non-null  int64  \n",
      " 95   NAME_GOODS_CATEGORY          123004 non-null  int64  \n",
      " 96   NAME_PORTFOLIO               123004 non-null  int64  \n",
      " 97   NAME_PRODUCT_TYPE            123004 non-null  int64  \n",
      " 98   CHANNEL_TYPE                 123004 non-null  int64  \n",
      " 99   SELLERPLACE_AREA             123004 non-null  int64  \n",
      " 100  NAME_SELLER_INDUSTRY         123004 non-null  int64  \n",
      " 101  CNT_PAYMENT                  123004 non-null  float64\n",
      " 102  NAME_YIELD_GROUP             123004 non-null  int64  \n",
      " 103  PRODUCT_COMBINATION          123004 non-null  int64  \n",
      " 104  CNT_INSTALMENT               123004 non-null  float64\n",
      " 105  CNT_INSTALMENT_FUTURE        123004 non-null  float64\n",
      " 106  SK_DPD                       123004 non-null  int64  \n",
      " 107  SK_DPD_DEF                   123004 non-null  int64  \n",
      " 108  NUM_INSTALMENT_VERSION       123004 non-null  float64\n",
      " 109  NUM_INSTALMENT_NUMBER        123004 non-null  int64  \n",
      " 110  DAYS_INSTALMENT              123004 non-null  float64\n",
      " 111  DAYS_ENTRY_PAYMENT           123004 non-null  float64\n",
      " 112  AMT_INSTALMENT               123004 non-null  float64\n",
      " 113  AMT_PAYMENT                  123004 non-null  float64\n",
      " 114  AMT_BALANCE                  123004 non-null  float64\n",
      " 115  AMT_CREDIT_LIMIT_ACTUAL      123004 non-null  int64  \n",
      " 116  AMT_DRAWINGS_ATM_CURRENT     123004 non-null  float64\n",
      " 117  AMT_DRAWINGS_CURRENT         123004 non-null  float64\n",
      " 118  AMT_DRAWINGS_OTHER_CURRENT   123004 non-null  float64\n",
      " 119  AMT_DRAWINGS_POS_CURRENT     123004 non-null  float64\n",
      " 120  AMT_INST_MIN_REGULARITY      123004 non-null  float64\n",
      " 121  AMT_PAYMENT_CURRENT          123004 non-null  float64\n",
      " 122  AMT_PAYMENT_TOTAL_CURRENT    123004 non-null  float64\n",
      " 123  AMT_RECEIVABLE_PRINCIPAL     123004 non-null  float64\n",
      " 124  AMT_RECIVABLE                123004 non-null  float64\n",
      " 125  AMT_TOTAL_RECEIVABLE         123004 non-null  float64\n",
      " 126  CNT_DRAWINGS_ATM_CURRENT     123004 non-null  float64\n",
      " 127  CNT_DRAWINGS_CURRENT         123004 non-null  int64  \n",
      " 128  CNT_DRAWINGS_OTHER_CURRENT   123004 non-null  float64\n",
      " 129  CNT_DRAWINGS_POS_CURRENT     123004 non-null  float64\n",
      " 130  CNT_INSTALMENT_MATURE_CUM    123004 non-null  float64\n",
      "dtypes: float64(48), int64(83)\n",
      "memory usage: 123.9 MB\n"
     ]
    }
   ],
   "source": [
    "X_train.info(max_cols=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importando a biblioteca\n",
    "from sklearn.preprocessing import  StandardScaler\n",
    "\n",
    "# instancioando o escalador\n",
    "scaler = StandardScaler()\n",
    "X_train_normalizado = scaler.fit_transform(X_train)\n",
    "X_train_normalizado = pd.DataFrame(X_train_normalizado, columns = X_train.columns)\n",
    "\n",
    "y_train_normalizado = y_train.copy()\n",
    "\n",
    "X_test_normalizado  = scaler.fit_transform(X_test)\n",
    "X_test_normalizado  = pd.DataFrame(X_test_normalizado, columns =X_test.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Seleção de Parâmetros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número ótimo de features: 37\n",
      "Colunas selecionadas: ['NAME_CONTRACT_TYPE', 'CODE_GENDER', 'FLAG_OWN_CAR', 'AMT_INCOME_TOTAL', 'AMT_CREDIT', 'AMT_ANNUITY', 'AMT_GOODS_PRICE', 'NAME_INCOME_TYPE', 'NAME_EDUCATION_TYPE', 'NAME_FAMILY_STATUS', 'DAYS_BIRTH', 'DAYS_EMPLOYED', 'DAYS_ID_PUBLISH', 'FLAG_WORK_PHONE', 'FLAG_PHONE', 'REGION_RATING_CLIENT', 'REGION_RATING_CLIENT_W_CITY', 'HOUR_APPR_PROCESS_START', 'REG_CITY_NOT_LIVE_CITY', 'REG_CITY_NOT_WORK_CITY', 'EXT_SOURCE_2', 'EXT_SOURCE_3', 'DEF_30_CNT_SOCIAL_CIRCLE', 'DEF_60_CNT_SOCIAL_CIRCLE', 'DAYS_LAST_PHONE_CHANGE', 'FLAG_DOCUMENT_3', 'FLAG_DOCUMENT_13', 'FLAG_DOCUMENT_18', 'AMT_REQ_CREDIT_BUREAU_DAY', 'AMT_REQ_CREDIT_BUREAU_WEEK', 'AMT_REQ_CREDIT_BUREAU_QRT', 'AMT_REQ_CREDIT_BUREAU_YEAR', 'SK_ID_BUREAU', 'DAYS_CREDIT', 'DAYS_DECISION', 'AMT_DRAWINGS_CURRENT', 'AMT_INST_MIN_REGULARITY']\n"
     ]
    }
   ],
   "source": [
    "#Importação biblioteca\n",
    "from sklearn.feature_selection import RFE, RFECV\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from xgboost                import XGBClassifier            # XGBClassifier           \n",
    "\n",
    "\n",
    "#Atribuição do melhor modelo selecionado\n",
    "modelo_base = XGBClassifier(random_state   = 42,    # semente para reprodutibilidade\n",
    "                            learning_rate  = 0.1,   # taxa de aprendizado\n",
    "                            max_depth      = 4,     # profundidade máxima da árvore\n",
    "                            n_estimators   = 100,   # número de árvores a serem construídas\n",
    "                            subsample      = 0.8)   # fração de amostras a serem usadas para treinar cada árvore\n",
    "\n",
    "#RFE com validação cruzada\n",
    "cv = StratifiedKFold(n_splits = validacao_cruzada_num_folds)\n",
    "rfecv = RFECV(estimator = modelo_base, step=1, cv = cv, min_features_to_select = 20, n_jobs=-1)\n",
    "\n",
    "#Treino\n",
    "rfecv.fit(X_train_normalizado, y_train_normalizado)\n",
    "\n",
    "# Resultados\n",
    "print(\"Número ótimo de features:\", rfecv.n_features_)\n",
    "colunas_selecionadas = X_train_normalizado.columns[rfecv.support_]\n",
    "print(\"Colunas selecionadas:\", colunas_selecionadas.tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_normalizado_colunasSelecionadas = X_train_normalizado[colunas_selecionadas]\n",
    "y_train_normalizado_colunasSelecionadas = y_train_normalizado.copy()\n",
    "X_test_normalizado_colunasSelecionadas  = X_test_normalizado[colunas_selecionadas]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 123004 entries, 0 to 123003\n",
      "Data columns (total 37 columns):\n",
      " #   Column                       Non-Null Count   Dtype  \n",
      "---  ------                       --------------   -----  \n",
      " 0   NAME_CONTRACT_TYPE           123004 non-null  float64\n",
      " 1   CODE_GENDER                  123004 non-null  float64\n",
      " 2   FLAG_OWN_CAR                 123004 non-null  float64\n",
      " 3   AMT_INCOME_TOTAL             123004 non-null  float64\n",
      " 4   AMT_CREDIT                   123004 non-null  float64\n",
      " 5   AMT_ANNUITY                  123004 non-null  float64\n",
      " 6   AMT_GOODS_PRICE              123004 non-null  float64\n",
      " 7   NAME_INCOME_TYPE             123004 non-null  float64\n",
      " 8   NAME_EDUCATION_TYPE          123004 non-null  float64\n",
      " 9   NAME_FAMILY_STATUS           123004 non-null  float64\n",
      " 10  DAYS_BIRTH                   123004 non-null  float64\n",
      " 11  DAYS_EMPLOYED                123004 non-null  float64\n",
      " 12  DAYS_ID_PUBLISH              123004 non-null  float64\n",
      " 13  FLAG_WORK_PHONE              123004 non-null  float64\n",
      " 14  FLAG_PHONE                   123004 non-null  float64\n",
      " 15  REGION_RATING_CLIENT         123004 non-null  float64\n",
      " 16  REGION_RATING_CLIENT_W_CITY  123004 non-null  float64\n",
      " 17  HOUR_APPR_PROCESS_START      123004 non-null  float64\n",
      " 18  REG_CITY_NOT_LIVE_CITY       123004 non-null  float64\n",
      " 19  REG_CITY_NOT_WORK_CITY       123004 non-null  float64\n",
      " 20  EXT_SOURCE_2                 123004 non-null  float64\n",
      " 21  EXT_SOURCE_3                 123004 non-null  float64\n",
      " 22  DEF_30_CNT_SOCIAL_CIRCLE     123004 non-null  float64\n",
      " 23  DEF_60_CNT_SOCIAL_CIRCLE     123004 non-null  float64\n",
      " 24  DAYS_LAST_PHONE_CHANGE       123004 non-null  float64\n",
      " 25  FLAG_DOCUMENT_3              123004 non-null  float64\n",
      " 26  FLAG_DOCUMENT_13             123004 non-null  float64\n",
      " 27  FLAG_DOCUMENT_18             123004 non-null  float64\n",
      " 28  AMT_REQ_CREDIT_BUREAU_DAY    123004 non-null  float64\n",
      " 29  AMT_REQ_CREDIT_BUREAU_WEEK   123004 non-null  float64\n",
      " 30  AMT_REQ_CREDIT_BUREAU_QRT    123004 non-null  float64\n",
      " 31  AMT_REQ_CREDIT_BUREAU_YEAR   123004 non-null  float64\n",
      " 32  SK_ID_BUREAU                 123004 non-null  float64\n",
      " 33  DAYS_CREDIT                  123004 non-null  float64\n",
      " 34  DAYS_DECISION                123004 non-null  float64\n",
      " 35  AMT_DRAWINGS_CURRENT         123004 non-null  float64\n",
      " 36  AMT_INST_MIN_REGULARITY      123004 non-null  float64\n",
      "dtypes: float64(37)\n",
      "memory usage: 34.7 MB\n"
     ]
    }
   ],
   "source": [
    "X_train_normalizado_colunasSelecionadas.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n",
      "Index: 123004 entries, 245895 to 170348\n",
      "Series name: TARGET\n",
      "Non-Null Count   Dtype\n",
      "--------------   -----\n",
      "123004 non-null  int64\n",
      "dtypes: int64(1)\n",
      "memory usage: 1.9 MB\n"
     ]
    }
   ],
   "source": [
    "y_train_normalizado_colunasSelecionadas.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p6uN3N9GhN8x"
   },
   "source": [
    "# Aplicação XGBOOST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importando Bibliotecas pertinentes\n",
    "from xgboost                 import XGBClassifier            # XGBClassifier \n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score, GridSearchCV \n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Avaliação do Modelo XGBoost\n",
    "\n",
    "# Definindo o cross-validation\n",
    "cross_validation = StratifiedKFold(n_splits=validacao_cruzada_num_folds,    # número de folds\n",
    "                                   shuffle=True,                            # embaralhar os dados\n",
    "                                   random_state=42)                         # semente para reprodutibilidade \n",
    "\n",
    "modelo_base = XGBClassifier(random_state   = 42,    # semente para reprodutibilidade\n",
    "                            learning_rate  = 0.1,   # taxa de aprendizado\n",
    "                            max_depth      = 4,     # profundidade máxima da árvore\n",
    "                            n_estimators   = 100,   # número de árvores a serem construídas\n",
    "                            subsample      = 0.8)   # fração de amostras a serem usadas para treinar cada árvore\n",
    "\n",
    "# Função para avaliar o modelo com validação cruzada\n",
    "def avaliar_modelo(modelo_base, X, y, nome=\"Modelo\"): \n",
    "    roc_auc = []   # Lista para armazenar as pontuações ROC AUC\n",
    "\n",
    "    # Realizando a validação cruzada\n",
    "    for train_idx, test_idx in cross_validation.split(X, y):   # Divisão dos dados em treino e teste\n",
    "        X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]  # Seleção dos dados de treino e teste\n",
    "        y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]  # Seleção dos rótulos de treino e teste\n",
    "        modelo_base.fit(X_train, y_train)                      # Treinamento do modelo\n",
    "        preds = modelo_base.predict(X_test)                    # Predição dos rótulos de teste\n",
    "        roc_auc.append(roc_auc_score(y_test, preds))           # Cálculo da pontuação ROC AUC\n",
    "\n",
    "        # Exibição da pontuação ROC AUC para o fold atual\n",
    "        print(f\"Fold {len(roc_auc)}: {roc_auc[-1]:.4f}\")  # Exibição da pontuação ROC AUC para o fold atual\n",
    "\n",
    "    # Exibição da média e desvio padrão das pontuações ROC AUC\n",
    "    print(f\"Após avaliação do modelo {nome}, temos:\")\n",
    "    print(f\"{nome}: roc_auc = {np.mean(roc_auc):.4f}, desvio padrão = {np.std(roc_auc):.4f}\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1: 0.5062\n",
      "Fold 2: 0.5036\n",
      "Fold 3: 0.5058\n",
      "Fold 4: 0.5117\n",
      "Fold 5: 0.5073\n",
      "Fold 6: 0.5029\n",
      "Fold 7: 0.5042\n",
      "Fold 8: 0.5051\n",
      "Fold 9: 0.5026\n",
      "Fold 10: 0.5068\n",
      "Após avaliação do modelo XGBoost, temos:\n",
      "XGBoost: roc_auc = 0.5056, desvio padrão = 0.0025\n"
     ]
    }
   ],
   "source": [
    "avaliar_modelo(modelo_base, X_train_normalizado_colunasSelecionadas, y_train_normalizado_colunasSelecionadas, \"XGBoost\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Treino e Teste com dados globais\n",
    "\n",
    "#Treino do Modelo com os dados de Teste Global\n",
    "modelo_base.fit(X_train_normalizado_colunasSelecionadas, y_train_normalizado_colunasSelecionadas)\n",
    "\n",
    "#Predição do Modelo com os dados de Teste Global\n",
    "preds   = modelo_base.predict(X_test_normalizado_colunasSelecionadas)\n",
    "\n",
    "#Geração do Data Frame das predições com o Teste Global\n",
    "df_test_XGBOOST = df_test.copy()\n",
    "df_test_XGBOOST[\"TARGET\"] = preds\n",
    "\n",
    "#Exibição do Data Frame que será enviado para o Kaggle\n",
    "df_test_XGBOOST[[\"SK_ID_CURR\",\"TARGET\"]]\n",
    "\n",
    "#Salvar o Data Frame que será enviado ao Kaggle em um arquivo .CSV\n",
    "df_test_XGBOOST[[\"SK_ID_CURR\",\"TARGET\"]].to_csv(\"df_test_XGBOOST.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aplicação REGRESSÃO LOGÍSTICA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importando Bibliotecas pertinentes\n",
    "from sklearn.linear_model   import LogisticRegression, LogisticRegressionCV     # Regressão Logística\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score, GridSearchCV \n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Avaliação do Modelo Regressão Logística\n",
    "\n",
    "# Definindo o cross-validation\n",
    "cross_validation = StratifiedKFold(n_splits=validacao_cruzada_num_folds,    # número de folds\n",
    "                                   shuffle=True,                            # embaralhar os dados\n",
    "                                   random_state=42)                         # semente para reprodutibilidade \n",
    "\n",
    "modelo_base = LogisticRegression(random_state   = 42)    # semente para reprodutibilidade\n",
    "                            \n",
    "\n",
    "# Função para avaliar o modelo com validação cruzada\n",
    "def avaliar_modelo(modelo_base, X, y, nome=\"Modelo\"): \n",
    "    roc_auc = []   # Lista para armazenar as pontuações ROC AUC\n",
    "\n",
    "    # Realizando a validação cruzada\n",
    "    for train_idx, test_idx in cross_validation.split(X, y):   # Divisão dos dados em treino e teste\n",
    "        X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]  # Seleção dos dados de treino e teste\n",
    "        y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]  # Seleção dos rótulos de treino e teste\n",
    "        modelo_base.fit(X_train, y_train)                      # Treinamento do modelo\n",
    "        preds = modelo_base.predict(X_test)                    # Predição dos rótulos de teste\n",
    "        roc_auc.append(roc_auc_score(y_test, preds))           # Cálculo da pontuação ROC AUC\n",
    "\n",
    "        # Exibição da pontuação ROC AUC para o fold atual\n",
    "        print(f\"Fold {len(roc_auc)}: {roc_auc[-1]:.4f}\")  # Exibição da pontuação ROC AUC para o fold atual\n",
    "\n",
    "    # Exibição da média e desvio padrão das pontuações ROC AUC\n",
    "    print(f\"Após avaliação do modelo {nome}, temos:\")\n",
    "    print(f\"{nome}: roc_auc = {np.mean(roc_auc):.4f}, desvio padrão = {np.std(roc_auc):.4f}\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1: 0.5071\n",
      "Fold 2: 0.5036\n",
      "Fold 3: 0.5046\n",
      "Fold 4: 0.5061\n",
      "Fold 5: 0.5062\n",
      "Fold 6: 0.5014\n",
      "Fold 7: 0.5028\n",
      "Fold 8: 0.5021\n",
      "Fold 9: 0.5029\n",
      "Fold 10: 0.5060\n",
      "Após avaliação do modelo Regressão Logística, temos:\n",
      "Regressão Logística: roc_auc = 0.5043, desvio padrão = 0.0019\n"
     ]
    }
   ],
   "source": [
    "avaliar_modelo(modelo_base, X_train_normalizado_colunasSelecionadas, y_train_normalizado_colunasSelecionadas, \"Regressão Logística\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Treino e Teste com dados globais\n",
    "\n",
    "#Treino do Modelo com os dados de Teste Global\n",
    "modelo_base.fit(X_train_normalizado_colunasSelecionadas, y_train_normalizado_colunasSelecionadas)\n",
    "\n",
    "#Predição do Modelo com os dados de Teste Global\n",
    "preds   = modelo_base.predict(X_test_normalizado_colunasSelecionadas)\n",
    "\n",
    "#Geração do Data Frame das predições com o Teste Global\n",
    "df_test_RegrassaoLogistica = df_test.copy()\n",
    "df_test_RegrassaoLogistica[\"TARGET\"] = preds\n",
    "\n",
    "#Exibição do Data Frame que será enviado para o Kaggle\n",
    "df_test_RegrassaoLogistica[[\"SK_ID_CURR\",\"TARGET\"]]\n",
    "\n",
    "#Salvar o Data Frame que será enviado ao Kaggle em um arquivo .CSV\n",
    "df_test_RegrassaoLogistica[[\"SK_ID_CURR\",\"TARGET\"]].to_csv(\"df_test_RegrassaoLogistica.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resultados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Como a escolha do valor de k afetou os resultados?<br>\n",
    "Resp.: Observa-se que para k menores não consegue-se uma boa separabilidade. Para K = 2, tem-se os centróides bem próximos fazendo com que os clusters se misturem. Já para K = 3, tem-se 2 centróides próximos e 1 mais separado, mostrando uma melhor separabilidad. Finalmente, para K = 4 tem-se 3 centroídes próximos e 1 mais afastado, mostrando separabilidade, mas bem semelhante a K =3. <br><br> \n",
    "\n",
    "> Os agrupamentos fazem sentido em termos práticos ou de negócio?<br>\n",
    "Resp.:Sim, pois os agrupamentos capturam perfis de clientes que fazem sentido para metas de negócio, e se tornam uma ferramenta poderosa para segmentação, personalização de ofertas e gestão de risco.<br><br>\n",
    "\n",
    "> Como o K-Means lidou com os dados do seu trabalho prático?\n",
    "Resp.: K‑Means “se encaixou” bem no seu caso prático, produzindo clusters interpretáveis e acionáveis. A análise dos centróides é possível fazer análise e delinear perfis.<br><br>\n",
    "\n",
    "> Os agrupamentos poderiam ser utilizados para melhorar de alguma forma o resultado da classificação?\n",
    "Resp.: Sim. Poderia-se usar o rótulo de cluster como nova feature, e depois de ajustar o K‑Means, você pode adicionar a coluna cluster ao seu conjunto de treino, e depois treinar o modelo como classificador."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "LhNgHgeP5bY5",
    "OIc6Rllz40KD"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
