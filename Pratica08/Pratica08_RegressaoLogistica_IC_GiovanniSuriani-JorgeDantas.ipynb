{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7QYddtZjGH_s"
   },
   "source": [
    "**Prática 08 – Regressão Logistica**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ghA_ViPQGH3r"
   },
   "source": [
    "**Alunos:\n",
    "\n",
    "GIOVANNI SURIANI FERREIRA\n",
    "\n",
    "JORGE ALIOMAR TROCOLI ABDON DANTAS**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lFr8QeByGHqO"
   },
   "source": [
    "Objetivo:<br>\n",
    "- Aplique classificador Regressão Logística aos dados seu Trabalho Prático.\n",
    "    - (https://scikitlearn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html)\n",
    "- Compare os resultados da Regressão Logística com os resultados do XGBoost (ou equivalente)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jzZ2MAv0hN8i"
   },
   "source": [
    "# PREPARAÇÃO DA BASE DE DADOS - Todos os dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "G3ZCBI41MkU5"
   },
   "outputs": [],
   "source": [
    "#Importando Bibliotecas Pandas e Numpy\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os, sys\n",
    "\n",
    "# Otimizador Giovanni\n",
    "#from sklearnex import patch_sklearn\n",
    "#patch_sklearn()\n",
    "\n",
    "#CSV_PATH = \"/home/gi/Desktop/Semestre8/Inteligencia_Computacional/TP1_csvs\" # Path Giovanni\n",
    "#validacao_cruzada_num_folds = 10 # Para Giovanni\n",
    "CSV_PATH = \"E:/Documentos/CEFET/OneDrive/Documentos/2ECOM067_INTELIGENCIA-COMPUTACIONAL-I_T01/TP1/bases/\" # Path Jorge\n",
    "validacao_cruzada_num_folds = 2 # Para Jorge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "232RQBEu3mWD"
   },
   "outputs": [],
   "source": [
    "#Carregando Base de dados principal - Treino\n",
    "df_train = pd.read_csv(f\"{CSV_PATH}/df_train_full.csv\")\n",
    "df_test  = pd.read_csv(f\"{CSV_PATH}/df_test_full.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DJjJF_XGhN8u"
   },
   "source": [
    "# PREPARAÇÃO DA BASE DE DADOS - Amostra"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verificação com colunas com muitos nulos (mais que 25%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calcular o % de nulos por coluna\n",
    "percentual_nulos = round(df_train.isnull().mean(),2)\n",
    "\n",
    "# Verificar quais colunas têm mais de 25% de valores nulos\n",
    "colunas_com_muitos_nulos = percentual_nulos[percentual_nulos > 0.25].index.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exclusão das coluna com muitos nulos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_tratado = df_train.copy()\n",
    "df_test_tratado  = df_test.copy()\n",
    "\n",
    "# Excluir colunas do treino\n",
    "df_train_tratado = df_train_tratado.drop(columns=colunas_com_muitos_nulos)\n",
    "\n",
    "# Excluir colunas do teste\n",
    "df_test_tratado = df_test_tratado.drop(columns=colunas_com_muitos_nulos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Substitutição dos nulos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de valores nulos restantes nos dados de treino: 0\n"
     ]
    }
   ],
   "source": [
    "#Tratar colunas numéricas - Treino\n",
    "for coluna in df_train_tratado.select_dtypes(include=['number']).columns:\n",
    "    if df_train_tratado[coluna].isnull().any():\n",
    "        if pd.api.types.is_float_dtype(df_train_tratado[coluna]): # Se tipo de dado for float, realizará a média\n",
    "            media = df_train_tratado[coluna].mean()\n",
    "            df_train_tratado[coluna] = df_train_tratado[coluna].fillna(media)\n",
    "        elif pd.api.types.is_integer_dtype(df_train_tratado[coluna]): # Se tipo de dado for int, realizará a moda\n",
    "            moda = df_train_tratado[coluna].mode(dropna=True)\n",
    "            if not moda.empty:\n",
    "                df_train_tratado[coluna] = df_train_tratado[coluna].fillna(moda[0])\n",
    "\n",
    "#Tratar colunas categóricas com a moda  - Treino\n",
    "colunas_categoricas = df_train_tratado.select_dtypes(include=['object', 'category']).columns\n",
    "\n",
    "for coluna in colunas_categoricas:\n",
    "    if df_train_tratado[coluna].isnull().any():\n",
    "        moda = df_train_tratado[coluna].mode(dropna=True)\n",
    "        if not moda.empty:\n",
    "            df_train_tratado[coluna] = df_train_tratado[coluna].fillna(moda[0])\n",
    "\n",
    "#Validação - Treino\n",
    "print(\"Total de valores nulos restantes nos dados de treino:\", df_train_tratado.isnull().sum().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de valores nulos restantes nos dados de teste: 0\n"
     ]
    }
   ],
   "source": [
    "#Tratar colunas numéricas - Teste\n",
    "for coluna in df_test_tratado.select_dtypes(include=['number']).columns:\n",
    "    if df_test_tratado[coluna].isnull().any():\n",
    "        if pd.api.types.is_float_dtype(df_test_tratado[coluna]): # Se tipo de dado for float, realizará a média\n",
    "            media = df_test_tratado[coluna].mean()\n",
    "            df_test_tratado[coluna] = df_test_tratado[coluna].fillna(media)\n",
    "        elif pd.api.types.is_integer_dtype(df_test_tratado[coluna]): # Se tipo de dado for int, realizará a moda\n",
    "            moda = df_test_tratado[coluna].mode(dropna=True)\n",
    "            if not moda.empty:\n",
    "                df_test_tratado[coluna] = df_test_tratado[coluna].fillna(moda[0])\n",
    "\n",
    "#Tratar colunas categóricas com a moda  - Teste\n",
    "colunas_categoricas = df_test_tratado.select_dtypes(include=['object', 'category']).columns\n",
    "\n",
    "for coluna in colunas_categoricas:\n",
    "    if df_test_tratado[coluna].isnull().any():\n",
    "        moda = df_test_tratado[coluna].mode(dropna=True)\n",
    "        if not moda.empty:\n",
    "            df_test_tratado[coluna] = df_test_tratado[coluna].fillna(moda[0])\n",
    "\n",
    "#Validação - Treino\n",
    "print(\"Total de valores nulos restantes nos dados de teste:\", df_test_tratado.isnull().sum().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Realizar transformação das variáveis categóricas em variáveis númericas (Label Enconder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importação da biblioteca\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le = LabelEncoder()\n",
    "\n",
    "#Busca dos atributos do tipo object e category - TREINO\n",
    "colunas_categoricas_train = df_train_tratado.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "\n",
    "#Concatenação dos dataframes treino e teste com o objetivo de realizar um label enconder com códigos únicos\n",
    "df_all = pd.concat([df_train_tratado, df_test_tratado], axis=0)\n",
    "\n",
    "for coluna in colunas_categoricas_train:\n",
    "    le.fit(df_all[coluna])\n",
    "    df_train_tratado[coluna] = le.transform(df_train_tratado[coluna].astype(str))\n",
    "    df_test_tratado[coluna] = le.transform(df_test_tratado[coluna].astype(str))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fazer amostragem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "42r9hUZuhN8v"
   },
   "outputs": [],
   "source": [
    "#Amostra df_train\n",
    "df_train_tratado_amostrado = df_train_tratado.sample(frac=0.001, random_state=42)  # Para Jorge\n",
    "#df_train_tratado_amostrado = df_train.sample(frac=1, random_state=42)  # Para Giovanni"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Divisão de Treino/Teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "kbmaTkxFhN8v"
   },
   "outputs": [],
   "source": [
    "#Divisão treino / teste\n",
    "X_train = df_train_tratado_amostrado.drop(columns={\"TARGET\"})\n",
    "y_train = df_train_tratado_amostrado.TARGET\n",
    "X_test  = df_test_tratado.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Verificar se y_train tem 0 e 1. Se true, OK dá para continuar a modelagem\n",
    "#                                Se false, ajustar para que tenha 0 e 1\n",
    "set(y_train) == {0, 1}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalização Padrão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importando a biblioteca\n",
    "from sklearn.preprocessing import  StandardScaler\n",
    "\n",
    "# instancioando o escalador\n",
    "scaler = StandardScaler()\n",
    "X_train_normalizado = scaler.fit_transform(X_train)\n",
    "X_train_normalizado = pd.DataFrame(X_train_normalizado, columns = X_train.columns)\n",
    "\n",
    "y_train_normalizado = y_train.copy()\n",
    "\n",
    "X_test_normalizado  = scaler.fit_transform(X_test)\n",
    "X_test_normalizado  = pd.DataFrame(X_test_normalizado, columns =X_test.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Seleção de Parâmetros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número ótimo de features: 39\n",
      "Colunas selecionadas: ['SK_ID_CURR', 'CODE_GENDER', 'AMT_INCOME_TOTAL', 'AMT_CREDIT', 'AMT_ANNUITY', 'AMT_GOODS_PRICE', 'NAME_EDUCATION_TYPE', 'REGION_POPULATION_RELATIVE', 'DAYS_BIRTH', 'DAYS_EMPLOYED', 'DAYS_REGISTRATION', 'DAYS_ID_PUBLISH', 'WEEKDAY_APPR_PROCESS_START', 'HOUR_APPR_PROCESS_START', 'ORGANIZATION_TYPE', 'EXT_SOURCE_2', 'EXT_SOURCE_3', 'DAYS_LAST_PHONE_CHANGE', 'FLAG_DOCUMENT_3', 'AMT_REQ_CREDIT_BUREAU_QRT', 'SK_ID_BUREAU', 'DAYS_CREDIT', 'DAYS_CREDIT_ENDDATE', 'AMT_CREDIT_SUM', 'AMT_CREDIT_SUM_DEBT', 'DAYS_CREDIT_UPDATE', 'MONTHS_BALANCE', 'SK_ID_PREV', 'AMT_APPLICATION', 'NAME_CONTRACT_STATUS', 'DAYS_DECISION', 'NAME_CLIENT_TYPE', 'SELLERPLACE_AREA', 'CNT_INSTALMENT_FUTURE', 'DAYS_INSTALMENT', 'DAYS_ENTRY_PAYMENT', 'AMT_INSTALMENT', 'AMT_PAYMENT', 'AMT_PAYMENT_CURRENT']\n"
     ]
    }
   ],
   "source": [
    "#Importação biblioteca\n",
    "from sklearn.feature_selection import RFE, RFECV\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "from xgboost                import XGBClassifier            # XGBClassifier           \n",
    "\n",
    "\n",
    "#Atribuição do melhor modelo selecionado\n",
    "modelo_base = XGBClassifier(random_state   = 42,    # semente para reprodutibilidade\n",
    "                            learning_rate  = 0.1,   # taxa de aprendizado\n",
    "                            max_depth      = 4,     # profundidade máxima da árvore\n",
    "                            n_estimators   = 100,   # número de árvores a serem construídas\n",
    "                            subsample      = 0.8)   # fração de amostras a serem usadas para treinar cada árvore\n",
    "\n",
    "#RFE com validação cruzada\n",
    "cv = StratifiedKFold(n_splits = validacao_cruzada_num_folds)\n",
    "rfecv = RFECV(estimator = modelo_base, step=1, cv = cv, min_features_to_select = 20, n_jobs=-1)\n",
    "\n",
    "#Treino\n",
    "rfecv.fit(X_train_normalizado, y_train_normalizado)\n",
    "\n",
    "# Resultados\n",
    "print(\"Número ótimo de features:\", rfecv.n_features_)\n",
    "colunas_selecionadas = X_train_normalizado.columns[rfecv.support_]\n",
    "print(\"Colunas selecionadas:\", colunas_selecionadas.tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_normalizado_colunasSelecionadas = X_train_normalizado[colunas_selecionadas]\n",
    "y_train_normalizado_colunasSelecionadas = y_train_normalizado.copy()\n",
    "X_test_normalizado_colunasSelecionadas  = X_test_normalizado[colunas_selecionadas]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 308 entries, 0 to 307\n",
      "Data columns (total 39 columns):\n",
      " #   Column                      Non-Null Count  Dtype  \n",
      "---  ------                      --------------  -----  \n",
      " 0   SK_ID_CURR                  308 non-null    float64\n",
      " 1   CODE_GENDER                 308 non-null    float64\n",
      " 2   AMT_INCOME_TOTAL            308 non-null    float64\n",
      " 3   AMT_CREDIT                  308 non-null    float64\n",
      " 4   AMT_ANNUITY                 308 non-null    float64\n",
      " 5   AMT_GOODS_PRICE             308 non-null    float64\n",
      " 6   NAME_EDUCATION_TYPE         308 non-null    float64\n",
      " 7   REGION_POPULATION_RELATIVE  308 non-null    float64\n",
      " 8   DAYS_BIRTH                  308 non-null    float64\n",
      " 9   DAYS_EMPLOYED               308 non-null    float64\n",
      " 10  DAYS_REGISTRATION           308 non-null    float64\n",
      " 11  DAYS_ID_PUBLISH             308 non-null    float64\n",
      " 12  WEEKDAY_APPR_PROCESS_START  308 non-null    float64\n",
      " 13  HOUR_APPR_PROCESS_START     308 non-null    float64\n",
      " 14  ORGANIZATION_TYPE           308 non-null    float64\n",
      " 15  EXT_SOURCE_2                308 non-null    float64\n",
      " 16  EXT_SOURCE_3                308 non-null    float64\n",
      " 17  DAYS_LAST_PHONE_CHANGE      308 non-null    float64\n",
      " 18  FLAG_DOCUMENT_3             308 non-null    float64\n",
      " 19  AMT_REQ_CREDIT_BUREAU_QRT   308 non-null    float64\n",
      " 20  SK_ID_BUREAU                308 non-null    float64\n",
      " 21  DAYS_CREDIT                 308 non-null    float64\n",
      " 22  DAYS_CREDIT_ENDDATE         308 non-null    float64\n",
      " 23  AMT_CREDIT_SUM              308 non-null    float64\n",
      " 24  AMT_CREDIT_SUM_DEBT         308 non-null    float64\n",
      " 25  DAYS_CREDIT_UPDATE          308 non-null    float64\n",
      " 26  MONTHS_BALANCE              308 non-null    float64\n",
      " 27  SK_ID_PREV                  308 non-null    float64\n",
      " 28  AMT_APPLICATION             308 non-null    float64\n",
      " 29  NAME_CONTRACT_STATUS        308 non-null    float64\n",
      " 30  DAYS_DECISION               308 non-null    float64\n",
      " 31  NAME_CLIENT_TYPE            308 non-null    float64\n",
      " 32  SELLERPLACE_AREA            308 non-null    float64\n",
      " 33  CNT_INSTALMENT_FUTURE       308 non-null    float64\n",
      " 34  DAYS_INSTALMENT             308 non-null    float64\n",
      " 35  DAYS_ENTRY_PAYMENT          308 non-null    float64\n",
      " 36  AMT_INSTALMENT              308 non-null    float64\n",
      " 37  AMT_PAYMENT                 308 non-null    float64\n",
      " 38  AMT_PAYMENT_CURRENT         308 non-null    float64\n",
      "dtypes: float64(39)\n",
      "memory usage: 94.0 KB\n"
     ]
    }
   ],
   "source": [
    "X_train_normalizado_colunasSelecionadas.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n",
      "Index: 308 entries, 245895 to 194273\n",
      "Series name: TARGET\n",
      "Non-Null Count  Dtype\n",
      "--------------  -----\n",
      "308 non-null    int64\n",
      "dtypes: int64(1)\n",
      "memory usage: 4.8 KB\n"
     ]
    }
   ],
   "source": [
    "y_train_normalizado_colunasSelecionadas.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p6uN3N9GhN8x"
   },
   "source": [
    "# Aplicação XGBOOST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importando Bibliotecas pertinentes\n",
    "from xgboost                 import XGBClassifier            # XGBClassifier \n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score, GridSearchCV \n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Avaliação do Modelo XGBoost\n",
    "\n",
    "# Definindo o cross-validation\n",
    "cross_validation = StratifiedKFold(n_splits=validacao_cruzada_num_folds,    # número de folds\n",
    "                                   shuffle=True,                            # embaralhar os dados\n",
    "                                   random_state=42)                         # semente para reprodutibilidade \n",
    "\n",
    "modelo_base = XGBClassifier(random_state   = 42,    # semente para reprodutibilidade\n",
    "                            learning_rate  = 0.1,   # taxa de aprendizado\n",
    "                            max_depth      = 4,     # profundidade máxima da árvore\n",
    "                            n_estimators   = 100,   # número de árvores a serem construídas\n",
    "                            subsample      = 0.8)   # fração de amostras a serem usadas para treinar cada árvore\n",
    "\n",
    "# Função para avaliar o modelo com validação cruzada\n",
    "def avaliar_modelo(modelo_base, X, y, nome=\"Modelo\"): \n",
    "    roc_auc = []   # Lista para armazenar as pontuações ROC AUC\n",
    "\n",
    "    # Realizando a validação cruzada\n",
    "    for train_idx, test_idx in cross_validation.split(X, y):   # Divisão dos dados em treino e teste\n",
    "        X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]  # Seleção dos dados de treino e teste\n",
    "        y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]  # Seleção dos rótulos de treino e teste\n",
    "        modelo_base.fit(X_train, y_train)                      # Treinamento do modelo\n",
    "        preds = modelo_base.predict(X_test)                    # Predição dos rótulos de teste\n",
    "        roc_auc.append(roc_auc_score(y_test, preds))           # Cálculo da pontuação ROC AUC\n",
    "\n",
    "        # Exibição da pontuação ROC AUC para o fold atual\n",
    "        print(f\"Fold {len(roc_auc)}: {roc_auc[-1]:.4f}\")  # Exibição da pontuação ROC AUC para o fold atual\n",
    "\n",
    "    # Exibição da média e desvio padrão das pontuações ROC AUC\n",
    "    print(f\"Após avaliação do modelo {nome}, temos:\")\n",
    "    print(f\"{nome}: roc_auc = {np.mean(roc_auc):.4f}, desvio padrão = {np.std(roc_auc):.4f}\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1: 0.5276\n",
      "Fold 2: 0.5809\n",
      "Após avaliação do modelo XGBoost, temos:\n",
      "XGBoost: roc_auc = 0.5543, desvio padrão = 0.0267\n"
     ]
    }
   ],
   "source": [
    "avaliar_modelo(modelo_base, X_train_normalizado_colunasSelecionadas, y_train_normalizado_colunasSelecionadas, \"XGBoost\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Treino e Teste com dados globais\n",
    "\n",
    "#Treino do Modelo com os dados de Teste Global\n",
    "modelo_base.fit(X_train_normalizado_colunasSelecionadas, y_train_normalizado_colunasSelecionadas)\n",
    "\n",
    "#Predição do Modelo com os dados de Teste Global\n",
    "preds   = modelo_base.predict(X_test_normalizado_colunasSelecionadas)\n",
    "\n",
    "#Geração do Data Frame das predições com o Teste Global\n",
    "df_test_XGBOOST = df_test.copy()\n",
    "df_test_XGBOOST[\"TARGET\"] = preds\n",
    "\n",
    "#Exibição do Data Frame que será enviado para o Kaggle\n",
    "df_test_XGBOOST[[\"SK_ID_CURR\",\"TARGET\"]]\n",
    "\n",
    "#Salvar o Data Frame que será enviado ao Kaggle em um arquivo .CSV\n",
    "df_test_XGBOOST[[\"SK_ID_CURR\",\"TARGET\"]].to_csv(\"df_test_XGBOOST.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aplicação REGRESSÃO LOGÍSTICA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importando Bibliotecas pertinentes\n",
    "from sklearn.linear_model   import LogisticRegression, LogisticRegressionCV     # Regressão Logística\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score, GridSearchCV \n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Avaliação do Modelo Regressão Logística\n",
    "\n",
    "# Definindo o cross-validation\n",
    "cross_validation = StratifiedKFold(n_splits=validacao_cruzada_num_folds,    # número de folds\n",
    "                                   shuffle=True,                            # embaralhar os dados\n",
    "                                   random_state=42)                         # semente para reprodutibilidade \n",
    "\n",
    "modelo_base = LogisticRegression(random_state   = 42)    # semente para reprodutibilidade\n",
    "                            \n",
    "\n",
    "# Função para avaliar o modelo com validação cruzada\n",
    "def avaliar_modelo(modelo_base, X, y, nome=\"Modelo\"): \n",
    "    roc_auc = []   # Lista para armazenar as pontuações ROC AUC\n",
    "\n",
    "    # Realizando a validação cruzada\n",
    "    for train_idx, test_idx in cross_validation.split(X, y):   # Divisão dos dados em treino e teste\n",
    "        X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]  # Seleção dos dados de treino e teste\n",
    "        y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]  # Seleção dos rótulos de treino e teste\n",
    "        modelo_base.fit(X_train, y_train)                      # Treinamento do modelo\n",
    "        preds = modelo_base.predict(X_test)                    # Predição dos rótulos de teste\n",
    "        roc_auc.append(roc_auc_score(y_test, preds))           # Cálculo da pontuação ROC AUC\n",
    "\n",
    "        # Exibição da pontuação ROC AUC para o fold atual\n",
    "        print(f\"Fold {len(roc_auc)}: {roc_auc[-1]:.4f}\")  # Exibição da pontuação ROC AUC para o fold atual\n",
    "\n",
    "    # Exibição da média e desvio padrão das pontuações ROC AUC\n",
    "    print(f\"Após avaliação do modelo {nome}, temos:\")\n",
    "    print(f\"{nome}: roc_auc = {np.mean(roc_auc):.4f}, desvio padrão = {np.std(roc_auc):.4f}\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1: 0.7319\n",
      "Fold 2: 0.6473\n",
      "Após avaliação do modelo Regressão Logística, temos:\n",
      "Regressão Logística: roc_auc = 0.6896, desvio padrão = 0.0423\n"
     ]
    }
   ],
   "source": [
    "avaliar_modelo(modelo_base, X_train_normalizado_colunasSelecionadas, y_train_normalizado_colunasSelecionadas, \"Regressão Logística\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Treino e Teste com dados globais\n",
    "\n",
    "#Treino do Modelo com os dados de Teste Global\n",
    "modelo_base.fit(X_train_normalizado_colunasSelecionadas, y_train_normalizado_colunasSelecionadas)\n",
    "\n",
    "#Predição do Modelo com os dados de Teste Global\n",
    "preds   = modelo_base.predict(X_test_normalizado_colunasSelecionadas)\n",
    "\n",
    "#Geração do Data Frame das predições com o Teste Global\n",
    "df_test_RegrassaoLogistica = df_test.copy()\n",
    "df_test_RegrassaoLogistica[\"TARGET\"] = preds\n",
    "\n",
    "#Exibição do Data Frame que será enviado para o Kaggle\n",
    "df_test_RegrassaoLogistica[[\"SK_ID_CURR\",\"TARGET\"]]\n",
    "\n",
    "#Salvar o Data Frame que será enviado ao Kaggle em um arquivo .CSV\n",
    "df_test_RegrassaoLogistica[[\"SK_ID_CURR\",\"TARGET\"]].to_csv(\"df_test_RegrassaoLogistica.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resultados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Como a escolha do valor de k afetou os resultados?<br>\n",
    "Resp.: Observa-se que para k menores não consegue-se uma boa separabilidade. Para K = 2, tem-se os centróides bem próximos fazendo com que os clusters se misturem. Já para K = 3, tem-se 2 centróides próximos e 1 mais separado, mostrando uma melhor separabilidad. Finalmente, para K = 4 tem-se 3 centroídes próximos e 1 mais afastado, mostrando separabilidade, mas bem semelhante a K =3. <br><br> \n",
    "\n",
    "> Os agrupamentos fazem sentido em termos práticos ou de negócio?<br>\n",
    "Resp.:Sim, pois os agrupamentos capturam perfis de clientes que fazem sentido para metas de negócio, e se tornam uma ferramenta poderosa para segmentação, personalização de ofertas e gestão de risco.<br><br>\n",
    "\n",
    "> Como o K-Means lidou com os dados do seu trabalho prático?\n",
    "Resp.: K‑Means “se encaixou” bem no seu caso prático, produzindo clusters interpretáveis e acionáveis. A análise dos centróides é possível fazer análise e delinear perfis.<br><br>\n",
    "\n",
    "> Os agrupamentos poderiam ser utilizados para melhorar de alguma forma o resultado da classificação?\n",
    "Resp.: Sim. Poderia-se usar o rótulo de cluster como nova feature, e depois de ajustar o K‑Means, você pode adicionar a coluna cluster ao seu conjunto de treino, e depois treinar o modelo como classificador."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "LhNgHgeP5bY5",
    "OIc6Rllz40KD"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
